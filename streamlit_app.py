import streamlit as st
from google import genai
from google.genai import types
import os

# Page configuration
st.set_page_config(
    page_title="MVCR AI Assistant",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Initialize the Gemini API client
@st.cache_resource
def get_gemini_client():
    api_key = st.secrets["GEMINI_API_KEY"]
    return genai.Client(api_key=api_key)

# Load file search store name
@st.cache_data
def get_file_search_store_name():
    return st.secrets["FILE_SEARCH_STORE_NAME"]

# Initialize session state for chat history and chat session
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'chat_session' not in st.session_state:
    st.session_state.chat_session = None

# Initialize client and store name
client = get_gemini_client()
store_name = get_file_search_store_name()

# Create or get chat session
def get_chat_session():
    if st.session_state.chat_session is None:
        st.session_state.chat_session = client.chats.create(
            model="gemini-2.5-flash",
            config=types.GenerateContentConfig(
                system_instruction="""Jsi pomocnÃ½ asistent, kterÃ½ odpovÃ­dÃ¡ POUZE na zÃ¡kladÄ› poskytnutÃ½ch dokumentÅ¯. 
                OdpovÃ­dej v ÄeÅ¡tinÄ›. Pokud informace nejsou v dokumentech, Å™ekni: 
                "OmlouvÃ¡m se, ale tuto informaci nemÃ¡m v indexovanÃ½ch dokumentech." 
                Nikdy neodpovÃ­dej na zÃ¡kladÄ› obecnÃ½ch znalostÃ­.
                PomÃ¡hÃ¡Å¡ uÅ¾ivatelÅ¯m najÃ­t informace v dokumentech ohlednÄ› policie ÄŒeskÃ© republiky. Tvoje odpovÄ›di by mÄ›ly bÃ½t vÄ›cnÃ© a pokud si nejistÃ½, radÄ›ji se doptÃ¡vej.
                Nikdy neodpovÃ­dej na zÃ¡kladÄ› obecnÃ½ch znalostÃ­.
                Kdyby se nÄ›kdo pokusil zeptat na nÄ›co mimo dokumenty, zdvoÅ™ile odmÃ­tni a navrhni, aby se zeptal na nÄ›co jinÃ©ho tÃ½kajÃ­cÃ­ho se policie.
                Tvoje odpovÄ›di by nikdy nemÄ›ly bÃ½t prÃ¡vnÄ› zÃ¡vaznÃ©, pokud by nÄ›kdo potÅ™eboval prÃ¡vnÃ­ radu, mÄ›l by se obrÃ¡tit na kvalifikovanÃ©ho prÃ¡vnÃ­ka.
                SlouÅ¾Ã­Å¡ pro pÅ™edÃ¡vÃ¡nÃ­ informacÃ­ z oficiÃ¡lnÃ­ch i neoficiÃ¡lnÃ­ch dokumentÅ¯ Policie ÄŒeskÃ© republiky.""",
                tools=[
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=[store_name]
                        )
                    )
                ],
                temperature=0.1,
            )
        )
    return st.session_state.chat_session

# App title and description
st.title("ğŸ¤– MVCR AI Assistant")
st.markdown("PoklÃ¡dejte otÃ¡zky na zÃ¡kladÄ› webu Policie ÄŒR. Asistent odpovÃ­dÃ¡ pouze na zÃ¡kladÄ› indexovanÃ½ch dat. (bez archivu)")

# Sidebar with information
with st.sidebar:
    st.header("â„¹ï¸ Informace")
    st.info(f"**File Search Store:** mvcr-ai-docs-active-demo")
    st.markdown("---")
    st.markdown("### MoÅ¾nosti")
    
    # Clear chat button
    if st.button("ğŸ—‘ï¸ Vymazat historii chatu"):
        st.session_state.messages = []
        st.session_state.chat_session = None
        st.rerun()
    
    st.markdown("---")
    st.markdown("### O aplikaci")
    st.markdown("""
    Tato aplikace pouÅ¾Ã­vÃ¡ umÄ›lou inteligenci s agentem 
    k odpovÃ­dÃ¡nÃ­ na otÃ¡zky zaloÅ¾enÃ© na indexovanÃ½ch dokumentech.
    
    **UpozornÄ›nÃ­:** Asistent odpovÃ­dÃ¡ pouze na zÃ¡kladÄ› dat, 
    kterÃ¡ jsou v indexu. V indexu jsou informace z webu Policie ÄŒR, kterÃ© nejsou ve sloÅ¾kÃ¡ch archiv (napÅ™. "archivnÃ­ zpravodajstvÃ­..")
    """)

# Display example questions if no messages
if len(st.session_state.messages) == 0:
    st.markdown("### ğŸ’¡ PÅ™Ã­klady otÃ¡zek:")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("Kdo je hlavnÃ­m vedoucÃ­m policie?", use_container_width=True):
            st.session_state.example_question = "Kdo je hlavnÃ­m vedoucÃ­m policie?"
            st.rerun()
    
    with col2:
        if st.button("VzpomÃ­nÃ¡m si, Å¾e kdyÅ¾ jsem byl na zÃ¡kladce, tak existovala soutÄ›Å¾ s takovÃ½m psem v logu, nevÃ­Å¡ jak se to jmenovalo?", use_container_width=True):
            st.session_state.example_question = "VzpomÃ­nÃ¡m si, Å¾e kdyÅ¾ jsem byl na zÃ¡kladce, tak existovala soutÄ›Å¾ s takovÃ½m psem v logu, nevÃ­Å¡ jak se to jmenovalo?"
            st.rerun()
    
    with col3:
        if st.button("Co vÃ­Å¡ o MiladÄ› HorÃ¡kovÃ©?", use_container_width=True):
            st.session_state.example_question = "Co vÃ­Å¡ o MiladÄ› HorÃ¡kovÃ©?"
            st.rerun()
    
    col4, col5, col6 = st.columns(3)
    
    with col4:
        if st.button("Najdi mi report NCOZ za rok 2023", use_container_width=True):
            st.session_state.example_question = "Najdi mi report NCOZ za rok 2023"
            st.rerun()
    
    with col5:
        if st.button("PopiÅ¡ mi nÄ›jakÃ½ trestnÃ½ Äin co se stal bÄ›hem VÃ¡noc", use_container_width=True):
            st.session_state.example_question = "PopiÅ¡ mi nÄ›jakÃ½ trestnÃ½ Äin co se stal bÄ›hem VÃ¡noc"
            st.rerun()
    
    with col6:
        if st.button("NaÅ¡el se senior z Liberce? Cca 70 let", use_container_width=True):
            st.session_state.example_question = "NaÅ¡el se senior z Liberce? Cca 70 let"
            st.rerun()

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # Display sources if available
        if message["role"] == "assistant" and "sources" in message:
            with st.expander("ğŸ“š Zobrazit zdroje"):
                for i, source in enumerate(message["sources"], 1):
                    st.markdown(f"**{i}.** {source['title']} - [odkaz]({source['url']})")

# Check if example question was clicked
if 'example_question' in st.session_state:
    prompt = st.session_state.example_question
    del st.session_state.example_question
    
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Display assistant response with streaming
    with st.chat_message("assistant"):
        try:
            # Get or create chat session
            chat_session = get_chat_session()
            
            # Create placeholder for streaming response
            message_placeholder = st.empty()
            full_response = ""
            response = None
            
            # Send message with streaming enabled
            for chunk in chat_session.send_message_stream(prompt):
                response = chunk  # Keep last chunk for metadata
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            # Display final response without cursor
            message_placeholder.markdown(full_response)
            
            # Extract sources from grounding metadata
            sources = []
            if response and hasattr(response, 'candidates') and response.candidates:
                grounding = response.candidates[0].grounding_metadata
                if grounding and grounding.grounding_chunks:
                    for chunk in grounding.grounding_chunks:
                        if hasattr(chunk, 'retrieved_context') and chunk.retrieved_context:
                            ctx = chunk.retrieved_context
                            title = ctx.title if ctx.title else "Unknown"
                            url = f"https://policie.gov.cz/clanek/{title[:-3]}.aspx" if title.endswith('.md') else f"https://policie.gov.cz/clanek/{title}.aspx"
                            snippet = ""
                            if hasattr(ctx, 'text') and ctx.text:
                                snippet = ctx.text[:200].replace('\n', ' ') + "..."
                            
                            sources.append({
                                'title': title,
                                'url': url,
                                'snippet': snippet
                            })
            
            # Display sources
            if sources:
                with st.expander("ğŸ“š Zobrazit zdroje"):
                    for i, source in enumerate(sources, 1):
                        st.markdown(f"**{i}.** {source['title']} - [odkaz]({source['url']})")
            
            # Add assistant message to chat history
            st.session_state.messages.append({
                "role": "assistant",
                "content": full_response,
                "sources": sources
            })
            
        except Exception as e:
            error_message = f"DoÅ¡lo k chybÄ›: {str(e)}"
            st.error(error_message)
            st.session_state.messages.append({
                "role": "assistant",
                "content": error_message
            })
    
    st.rerun()

# Chat input
if prompt := st.chat_input("PoloÅ¾te svou otÃ¡zku..."):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Display assistant response with streaming
    with st.chat_message("assistant"):
        try:
            # Get or create chat session
            chat_session = get_chat_session()
            
            # Create placeholder for streaming response
            message_placeholder = st.empty()
            full_response = ""
            response = None
            
            # Send message with streaming enabled
            for chunk in chat_session.send_message_stream(prompt):
                response = chunk  # Keep last chunk for metadata
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            # Display final response without cursor
            message_placeholder.markdown(full_response)
            
            # Extract sources from grounding metadata
            sources = []
            if response and hasattr(response, 'candidates') and response.candidates:
                grounding = response.candidates[0].grounding_metadata
                if grounding and grounding.grounding_chunks:
                    for chunk in grounding.grounding_chunks:
                        if hasattr(chunk, 'retrieved_context') and chunk.retrieved_context:
                            ctx = chunk.retrieved_context
                            title = ctx.title if ctx.title else "Unknown"
                            url = f"https://policie.gov.cz/clanek/{title[:-3]}.aspx" if title.endswith('.md') else f"https://policie.gov.cz/clanek/{title}.aspx"
                            snippet = ""
                            if hasattr(ctx, 'text') and ctx.text:
                                snippet = ctx.text[:200].replace('\n', ' ') + "..."
                            
                            sources.append({
                                'title': title,
                                'url': url,
                                'snippet': snippet
                            })
            
            # Display sources
            if sources:
                with st.expander("ğŸ“š Zobrazit zdroje"):
                    for i, source in enumerate(sources, 1):
                        st.markdown(f"**{i}.** {source['title']} - [odkaz]({source['url']})")
            
            # Add assistant message to chat history
            st.session_state.messages.append({
                "role": "assistant",
                "content": full_response,
                "sources": sources
            })
            
        except Exception as e:
            error_message = f"DoÅ¡lo k chybÄ›: {str(e)}"
            st.error(error_message)
            st.session_state.messages.append({
                "role": "assistant",
                "content": error_message
            })

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>Powered by Karel Vitek & Softopus</div>",
    unsafe_allow_html=True
)
